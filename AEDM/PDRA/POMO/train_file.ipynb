{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfe0007-4df3-4d66-a605-31f894b7a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-28 10:19:39] 671278574.py(111) : DEBUG_MODE: True\n",
      "[2025-11-28 10:19:39] 671278574.py(112) : USE_CUDA: False, CUDA_DEVICE_NUM: 0\n",
      "[2025-11-28 10:19:39] 671278574.py(113) : env_params{'problem_size': 197, 'pomo_size': 97, 'original_node_count': 98, 'link_count': 100}\n",
      "[2025-11-28 10:19:39] 671278574.py(113) : model_params{'embedding_dim': 128, 'sqrt_embedding_dim': 11.313708498984761, 'encoder_layer_num': 6, 'qkv_dim': 16, 'head_num': 8, 'logit_clipping': 10, 'ff_hidden_dim': 512, 'eval_type': 'softmax'}\n",
      "[2025-11-28 10:19:39] 671278574.py(113) : optimizer_params{'optimizer': {'lr': 0.0001, 'weight_decay': 1e-06}, 'scheduler': {'milestones': [8001, 8051], 'gamma': 0.1}}\n",
      "[2025-11-28 10:19:39] 671278574.py(113) : trainer_params{'use_cuda': False, 'cuda_device_num': 0, 'epochs': 4, 'train_episodes': 8, 'train_batch_size': 4, 'use_dynamic_vehicles': True, 'vehicle_config_range': {'num_vehicles': {'min': 2, 'max': 4}, 'vehicle_capacity': {'min': 1, 'max': 3}}, 'logging': {'model_save_interval': 500, 'img_save_interval': 500, 'log_image_params_1': {'json_foldername': 'log_image_style', 'filename': 'style_PDRA_20.json'}, 'log_image_params_2': {'json_foldername': 'log_image_style', 'filename': 'style_loss_1.json'}}, 'model_load': {'enable': False}}\n",
      "[2025-11-28 10:19:39] 671278574.py(113) : logger_params{'log_file': {'desc': 'train_PDRA_n100_dynamic_vehicles', 'filename': 'run_log', 'filepath': './result/20251128_111546_train_PDRA_n100_dynamic_vehicles'}}\n",
      "[2025-11-28 10:19:40] PDRATrainer.py(102) : =================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppGallery\\Anaconda\\envs\\d2l\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone configuration: {'num_vehicles': 4, 'vehicle_capacity': 1}\n",
      "Optimal path (batch_idx=2, pomo_idx=8): reward = 10.152105331420898\n",
      "Path node sequence: tensor([  0.,   9.,   0.,  96., 177.,  86., 162.,  76., 146.,  66., 130.,   0.,\n",
      "         67., 160.,  68., 175.,  69., 186.,  70., 196.,  80., 191.,  79., 185.,\n",
      "         78.,  77.,   0.,  88., 183.,  87., 184.,  97.,  95., 163.,  85., 147.,\n",
      "         75.,  76.,  66.,   0.,   0.,   0.,   0.,   0.,   0.])\n",
      "[2025-11-28 10:19:42] PDRATrainer.py(181) : Epoch   1: Train   4/  8(50.0%)  Score: 7.5849,  Loss: 0.0357\n",
      "Drone configuration: {'num_vehicles': 4, 'vehicle_capacity': 1}\n",
      "Optimal path (batch_idx=2, pomo_idx=72): reward = 9.921045303344727\n",
      "Path node sequence: tensor([  0.,  73., 186.,  72., 190.,  71.,  82., 191.,  81., 193.,   0.,  55.,\n",
      "        144.,  56.,  85.,  84.,   0.,  54., 154.,  55.,  64., 162.,  65.,  75.,\n",
      "        171.,  74.,   0.,  95., 179.,  85., 178.,  84., 185.,  94., 197.,  93.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])\n",
      "[2025-11-28 10:19:43] PDRATrainer.py(181) : Epoch   1: Train   8/  8(100.0%)  Score: 7.9787,  Loss: 0.0554\n",
      "[2025-11-28 10:19:43] PDRATrainer.py(186) : Epoch   1: Train (100%)  Score: 7.9787,  Loss: 0.0554\n",
      "[2025-11-28 10:19:43] PDRATrainer.py(116) : Epoch   1/  4: Time Est.: Elapsed[0.06m], Remain[0.19m]\n",
      "[2025-11-28 10:19:43] PDRATrainer.py(102) : =================================================================\n",
      "Drone configuration: {'num_vehicles': 4, 'vehicle_capacity': 1}\n",
      "Optimal path (batch_idx=1, pomo_idx=64): reward = 11.267321586608887\n",
      "Path node sequence: tensor([  0.,  65., 129.,  55., 116.,  45., 115.,  46., 128.,  56., 142.,  66.,\n",
      "        156.,   0.,  96., 180.,  86., 169.,  76.,  66.,   0.,  49., 155.,  48.,\n",
      "        141.,  47., 140.,  57., 154.,  58.,  67.,   0.,  78., 177.,  68., 176.,\n",
      "         69., 184.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])\n",
      "Drone configuration: {'num_vehicles': 2, 'vehicle_capacity': 1}\n",
      "Optimal path (batch_idx=2, pomo_idx=87): reward = 7.049012660980225\n",
      "Path node sequence: tensor([  0.,  88., 141.,  78., 129.,  68., 128.,  67., 140.,  77., 152.,   0.,\n",
      "         96., 173.,  86., 162.,  76., 151.,  66., 150.,  65., 160.,  75.,   0.,\n",
      "          0.,   0.,   0.])\n",
      "[2025-11-28 10:19:47] PDRATrainer.py(186) : Epoch   2: Train (100%)  Score: 6.9271,  Loss: 0.1163\n",
      "[2025-11-28 10:19:47] PDRATrainer.py(116) : Epoch   2/  4: Time Est.: Elapsed[0.12m], Remain[0.12m]\n",
      "[2025-11-28 10:19:47] PDRATrainer.py(125) : Saving log_image\n",
      "[2025-11-28 10:19:47] PDRATrainer.py(102) : =================================================================\n",
      "Drone configuration: {'num_vehicles': 4, 'vehicle_capacity': 3}\n",
      "Optimal path (batch_idx=0, pomo_idx=55): reward = 30.26898193359375\n",
      "Path node sequence: tensor([  0.,  56., 197.,  66., 143.,  67., 133.,  68., 124.,  58., 196.,  48.,\n",
      "        119.,  47., 128.,  46., 137.,  45., 146.,  44., 155.,  43., 195.,  53.,\n",
      "        164.,  54.,  23., 150.,  24., 141.,  25., 132.,  26., 123.,  27.,   0.,\n",
      "         66., 153.,  65., 163.,  64., 173.,  63., 181.,  62., 187.,  61.,  21.,\n",
      "        169.,  22., 159.,  23.,  11., 177.,  12., 168.,  13., 158.,  14., 149.,\n",
      "         15., 140.,  16., 131.,  17.,  16.,   0.,  75., 172.,  74., 180.,  73.,\n",
      "        186.,  72., 190.,  71.,  22.,  32., 156.,  33., 147.,  34., 138.,  35.,\n",
      "        129.,  36.,   0.,  90., 127.,  80., 118.,  70., 110.,  60., 103.,  50.,\n",
      "        104.,  49., 111.,  48.,   8., 121.,   9., 113.,  19., 106.,   0.])\n",
      "Drone configuration: {'num_vehicles': 3, 'vehicle_capacity': 2}\n",
      "Optimal path (batch_idx=0, pomo_idx=43): reward = 15.648808479309082\n",
      "Path node sequence: tensor([  0.,  44., 122.,  43., 123.,  33., 134.,  23., 196.,  24., 153.,  25.,\n",
      "        165.,  15.,  14.,  52.,   0.,  45., 133.,  44., 132.,  34., 143.,  35.,\n",
      "        155.,  36., 167.,  37.,  47., 156.,  46.,  53.,   0.,  93., 109.,  83.,\n",
      "        197.,  82., 105.,  72.,  99.,  73., 100.,  74., 107.,  84., 118.,  85.,\n",
      "        128.,  86.,  74.,  62.,  71.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])\n",
      "[2025-11-28 10:19:53] PDRATrainer.py(186) : Epoch   3: Train (100%)  Score: 19.2005,  Loss: 1.1552\n",
      "[2025-11-28 10:19:53] PDRATrainer.py(116) : Epoch   3/  4: Time Est.: Elapsed[0.23m], Remain[0.08m]\n",
      "[2025-11-28 10:19:53] PDRATrainer.py(125) : Saving log_image\n",
      "[2025-11-28 10:19:53] PDRATrainer.py(102) : =================================================================\n",
      "Drone configuration: {'num_vehicles': 3, 'vehicle_capacity': 2}\n",
      "Optimal path (batch_idx=2, pomo_idx=54): reward = 15.285077095031738\n",
      "Path node sequence: tensor([  0.,  55., 136.,  45., 126.,  46., 127.,  56., 137.,  66., 147.,  76.,\n",
      "        157.,  86.,  95., 177.,  85., 167.,  75., 156.,  65.,  54., 153.,  53.,\n",
      "        164.,  63.,  62.,   0.,  25., 151.,  24., 161.,  23., 171.,  22., 180.,\n",
      "         21.,  51., 173.,  52., 174.,  62., 182.,  72.,  62.,   0.,  11., 186.,\n",
      "         12., 179.,  13., 170.,  14., 160.,  15., 150.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.])\n",
      "Drone configuration: {'num_vehicles': 3, 'vehicle_capacity': 2}\n",
      "Optimal path (batch_idx=2, pomo_idx=48): reward = 18.712047576904297\n",
      "Path node sequence: tensor([  0.,  49., 100.,  48., 107.,  38., 116.,  28., 127.,  18., 139.,   8.,\n",
      "         15., 154.,  25., 155.,  24., 166.,   0.,  27., 126.,  37., 115.,  47.,\n",
      "        114.,  46., 125.,  45., 137.,  44., 147.,  43.,  33., 157.,  34., 146.,\n",
      "         35., 136.,  36., 135.,  26., 144.,  25., 195.,   0.,  51., 173.,  52.,\n",
      "        163.,  53., 153.,  54., 143.,  55., 134.,  56., 123.,  57.,  47.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])\n",
      "[2025-11-28 10:20:00] PDRATrainer.py(186) : Epoch   4: Train (100%)  Score: 14.7940,  Loss: -0.0020\n",
      "[2025-11-28 10:20:00] PDRATrainer.py(116) : Epoch   4/  4: Time Est.: Elapsed[0.33m], Remain[0.00m]\n",
      "[2025-11-28 10:20:00] PDRATrainer.py(125) : Saving log_image\n",
      "[2025-11-28 10:20:00] PDRATrainer.py(134) : Saving trained_model\n",
      "[2025-11-28 10:20:00] PDRATrainer.py(152) :  *** Training Done *** \n",
      "[2025-11-28 10:20:00] PDRATrainer.py(153) : Now, printing log array...\n",
      "[2025-11-28 10:20:00] utils.py(209) : train_score_list = [7.978688716888428, 6.927079200744629, 19.20051908493042, 14.794018268585205]\n",
      "[2025-11-28 10:20:00] utils.py(209) : train_loss_list = [0.05540483444929123, 0.11628828011453152, 1.1551505327224731, -0.0020032566972076893]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# Machine Environment Config\n",
    "\n",
    "DEBUG_MODE = True\n",
    "USE_CUDA = False\n",
    "CUDA_DEVICE_NUM = 0\n",
    "\n",
    "##########################################################################################\n",
    "# Path Config\n",
    "\n",
    "import os\n",
    "import sys\n",
    "__file__ = r\"C:\\Users\\gongh\\AEDM\\PDRA\\POMO\\train_file\"\n",
    "os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "sys.path.insert(0, \"..\")  # for problem_def\n",
    "sys.path.insert(0, \"../..\")  # for utils\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# import\n",
    "\n",
    "import logging\n",
    "from utils.utils import create_logger, copy_all_src\n",
    "\n",
    "from PDRATrainer import PDRATrainer as Trainer\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# parameters\n",
    "\n",
    "env_params = {\n",
    "    'problem_size': 197,         # 97 nodes + 1depot = 98\n",
    "    'pomo_size': 97,            \n",
    "    'original_node_count': 98,\n",
    "    'link_count': 100,           \n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    'embedding_dim': 128,\n",
    "    'sqrt_embedding_dim': 128**(1/2),\n",
    "    'encoder_layer_num': 6,\n",
    "    'qkv_dim': 16,\n",
    "    'head_num': 8,\n",
    "    'logit_clipping': 10,\n",
    "    'ff_hidden_dim': 512,\n",
    "    'eval_type': 'softmax',\n",
    "}\n",
    "\n",
    "optimizer_params = {'optimizer': {'lr': 1e-4,\n",
    "                                  'weight_decay': 1e-6},\n",
    "                    'scheduler': {'milestones': [8001, 8051],\n",
    "                                  'gamma': 0.1}}\n",
    "\n",
    "trainer_params = {\n",
    "    'use_cuda': USE_CUDA,\n",
    "    'cuda_device_num': CUDA_DEVICE_NUM,\n",
    "    'epochs': 20,\n",
    "    'train_episodes': 8,\n",
    "    'train_batch_size': 4,\n",
    "    \n",
    "    \n",
    "    'use_dynamic_vehicles': True,  \n",
    "    'vehicle_config_range': {'num_vehicles': {'min': 2, 'max': 4},           \n",
    "                             'vehicle_capacity': {'min': 1, 'max': 3}  \n",
    "                            },\n",
    "    \n",
    "    'logging': {'model_save_interval': 500,\n",
    "                'img_save_interval': 500,\n",
    "                'log_image_params_1': {'json_foldername': 'log_image_style',\n",
    "                                       'filename': 'style_PDRA_20.json'},\n",
    "                'log_image_params_2': {'json_foldername': 'log_image_style',\n",
    "                                       'filename': 'style_loss_1.json'},},\n",
    "    'model_load': {'enable': False,  # enable loading pre-trained model\n",
    "                    # 'path': './result/saved_PDRA20_model',  # directory path of pre-trained model and log files saved.\n",
    "                    # 'epoch': 2000,  # epoch version of pre-trained model to laod.\n",
    "                    }}\n",
    "\n",
    "logger_params = {'log_file': {'desc': 'train_PDRA_n100_dynamic_vehicles',  \n",
    "                              'filename': 'run_log'}}\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# main\n",
    "\n",
    "def main():\n",
    "    if DEBUG_MODE:\n",
    "        _set_debug_mode()\n",
    "\n",
    "    create_logger(**logger_params)\n",
    "    _print_config()\n",
    "\n",
    "    trainer = Trainer(env_params=env_params,\n",
    "                      model_params=model_params,\n",
    "                      optimizer_params=optimizer_params,\n",
    "                      trainer_params=trainer_params)\n",
    "\n",
    "    # copy_all_src(trainer.result_folder)\n",
    "\n",
    "    trainer.run()\n",
    "\n",
    "\n",
    "def _set_debug_mode():\n",
    "    global trainer_params\n",
    "    trainer_params['epochs'] = 4\n",
    "    trainer_params['train_episodes'] = 8\n",
    "    trainer_params['train_batch_size'] = 4\n",
    "\n",
    "\n",
    "def _print_config():\n",
    "    logger = logging.getLogger('root')\n",
    "    logger.info('DEBUG_MODE: {}'.format(DEBUG_MODE))\n",
    "    logger.info('USE_CUDA: {}, CUDA_DEVICE_NUM: {}'.format(USE_CUDA, CUDA_DEVICE_NUM))\n",
    "    [logger.info(g_key + \"{}\".format(globals()[g_key])) for g_key in globals().keys() if g_key.endswith('params')]\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892259f-8aab-4dfa-8be5-1f6a6156aed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23634d5-397d-4352-994e-cb20d3e393bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (d2l)",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
